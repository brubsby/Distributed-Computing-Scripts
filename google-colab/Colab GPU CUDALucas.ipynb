{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<h4>(1 - Recommend). Create and save new notebook(s) to enable automatic re-mounting of Drive storage. Copy and paste the below code into a <a href=\"http://colab.research.google.com/#create=true\" target=\"_parent\">new notebook</a> in Colab and follow the directions in the <a href=\"../#how-to-use\" target=\"_parent\">How To Use</a> section of the <em>README</em></h4><h4>(2). Open the pre-formed version in Colab (requires manual authorization each time a notebook is opened) <a href=\"https://colab.research.google.com/github/tdulcet/Distributed-Computing-Scripts/blob/master/google-colab/Colab%20GPU%20CUDALucas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title # **üìî Colab GPU and CPU Notebook**#{ vertical-output: true, display-mode: \"form\" }\n",
    "\n",
    "import os\n",
    "\n",
    "# @markdown #### ‚ÜñÔ∏è Click the ‚ñ∂Ô∏è button after deciding on the options below.\n",
    "# @markdown #### üîå Make sure the GPU is enabled under *Runtime‚ÜíChange runtime type*\n",
    "# @markdown #### üí° Keep each notebook **open** in the browser to prevent disconnection. üìå [the tab](https://support.mozilla.org/kb/pinned-tabs-keep-favorite-websites-open) or move them to a dedicated window for easy access.\n",
    "# @markdown #### ‚ÑπÔ∏è This notebook uses both our CUDALucas and MPrime [Bash install scripts](https://github.com/tdulcet/Distributed-Computing-Scripts#organizations) and our [PrimeNet Python program](https://github.com/tdulcet/Distributed-Computing-Scripts#primenet).\n",
    "# @markdown #### üìú Please see the [documentation](https://github.com/tdulcet/Distributed-Computing-Scripts/tree/master/google-colab) for more information and to ‚ù§Ô∏è support us.\n",
    "# @markdown #### ü§∑ Optionally, create a GIMPS/PrimeNet account [here](https://www.mersenne.org/update/) and [join](https://www.mersenne.org/jteam/) the ‚ÄúPortland State University‚Äù team!\n",
    "\n",
    "prime_ID = 'Default'  # @param ['Default'] {allow-input: true}\n",
    "computer_name = 'Default'  # @param ['Default'] {allow-input: true}\n",
    "GPU_type_of_work = '100 - First time LL tests'  # @param ['100 - First time LL tests', '101 - Double-check LL tests', '102 - World record LL tests', '104 - 100 million digit LL tests']\n",
    "CPU_type_of_work = '150 - First time PRP tests'  # @param ['0 - Whatever makes the most sense', '1 - Trial factoring to low limits', '2 - Trial factoring', '4 - P-1 factoring', '5 - ECM for first factors of Mersenne numbers', '6 - ECM on Fermat numbers', '8 - ECM on Mersenne cofactors', '100 - First time LL tests', '101 - Double-check LL tests', '102 - World record LL tests', '104 - 100 million digit LL tests', '150 - First time PRP tests', '151 - Double-check PRP tests', '152 - World record PRP tests', '153 - 100 million digit PRP tests', '154 - First time PRP tests that need P-1 factoring', '155 - Double-check tests using PRP with proof', '160 - First time PRP on Mersenne cofactors', '161 - Double-check PRP on Mersenne cofactors']\n",
    "CPU_prp_proof_power = '5'  # @param ['Default', '5', '6', '7', '8', '9', '10', '11', '12']\n",
    "CPU_prp_proof_power_mult = 'Default'  # @param ['Default', '1', '2', '3', '4']\n",
    "# @markdown Every lower power halves Drive storage requirements for PRP tests, but doubles the certification cost. Drive storage (GiB) needed for PRP tests:\n",
    "\n",
    "# @markdown Proof<br>Power | Exponent 50M | Exponent 100M | Exponent 150M | Exponent 200M | Exponent 250M | Exponent 300M | Exponent 332.1M<br>(100M digits)\n",
    "# @markdown --- | ---: | ---: | ---: | ---: | ---: | ---: | ---:\n",
    "# @markdown 5 | 0.186 | 0.372 | 0.558 | 0.745 | 0.931 | 1.117 | 1.237\n",
    "# @markdown 6 | 0.372 | 0.745 | 1.117 | 1.49 | 1.862 | 2.235 | 2.475\n",
    "# @markdown 7 | 0.745 | 1.49 | 2.235 | *2.98* | *3.725* | *4.47* | *4.95*\n",
    "# @markdown 8 | 1.49 | *2.98* | *4.47* | 5.96 | 7.45 | 8.94 | 9.9\n",
    "# @markdown 9 | ***2.98*** | **5.96** | 8.94 | 11.92 | 14.9 | 17.88 | 19.8\n",
    "# @markdown 10 | 5.96 | 11.92 | **17.88** | **23.84** | **29.8** | **35.76** | **39.6**\n",
    "# @markdown 11 | 11.92 | 23.84 | 35.76 | 47.68 | 59.6 | 71.52 | 79.2\n",
    "# @markdown 12 | 23.84 | 47.68 | 71.52 | 95.36 | 119.2 | 143 | 158.4\n",
    "CPU_proof_certification_work = True  # @param {type:\"boolean\"}\n",
    "computer_number = 'Default (1)'  # @param ['Default (1)', '2', '3', '4'] {allow-input: true}\n",
    "output_type = 'GPU (CUDALucas)'  # @param ['GPU and CPU', 'GPU (CUDALucas)', 'CPU (MPrime)']\n",
    "local_time = 'Pacific'  # @param ['Pacific', 'Mountain', 'Central', 'Eastern', 'Alaska', 'Hawaii']\n",
    "debug = 'False'  # @param ['False', 'GPU (CUDALucas)', 'CPU (MPrime)']\n",
    "\n",
    "# @markdown #### üêõ The *debug* option outputs GPU (CUDALucas) or CPU (Prime95/MPrime) progress and status, then exits.\n",
    "\n",
    "gpu_info = !nvidia-smi --query-gpu=gpu_name --format=csv,noheader # Output what GPU is assigned to this Notebook\n",
    "path_dir = ''  # helps us to not %cd in the optimize_gpu function\n",
    "\n",
    "\n",
    "class StopExecution(Exception):\n",
    "  def _render_traceback_(self):\n",
    "    pass\n",
    "\n",
    "\n",
    "def optimize_gpu():\n",
    "  '''If a new GPU is being used, optimize CUDALucas for using this GPU.'''\n",
    "  print('\\nOptimizing CUDALucas for this computer and GPU\\n')\n",
    "  os.chmod('cudalucas/CUDALucas', 0o777)\n",
    "  if not os.path.exists(f'{path_dir}cudalucas/{gpu_info} fft.txt'):\n",
    "    !cd cudalucas && ./CUDALucas -cufftbench 1024 8192 5\n",
    "  if not os.path.exists(f'{path_dir}cudalucas/{gpu_info} threads.txt'):\n",
    "    !cd cudalucas && ./CUDALucas -threadbench 1024 8192 5 0\n",
    "\n",
    "\n",
    "def run():\n",
    "  '''Run CUDALucas and MPrime.'''\n",
    "  print('\\nStarting PrimeNet\\n')\n",
    "  !cd cudalucas; nohup python3 -OO primenet.py -T {GPU_type_of_work} -l '{'local' + computer_number + '.ini'}' >> '{'primenet' + computer_number + '.out'}' &\n",
    "  !sleep 1\n",
    "  optimize_gpu()\n",
    "  while not os.path.exists(f'cudalucas/worktodo{computer_number}.txt'):\n",
    "    print(f\"Waiting for 'worktodo{computer_number}.txt' access...\")\n",
    "    !sleep 1\n",
    "\n",
    "  os.chmod('mprime_gpu/mprime', 0o777)\n",
    "  if output_type == 'GPU and CPU':\n",
    "    print('\\nStarting MPrime\\n')\n",
    "    !cd mprime_gpu; nohup ./mprime -A{computer_number} -d >> '{'cpu' + computer_number + '.out'}' &\n",
    "    print('\\nStarting CUDALucas\\n')\n",
    "    !cd cudalucas; nohup ./CUDALucas -i '{'CUDALucas' + computer_number + '.ini'}' >> '{'gpu' + computer_number + '.out'}' &\n",
    "    !tail -f '{'mprime_gpu/cpu' + computer_number + '.out'}' '{'cudalucas/primenet' + computer_number + '.out'}' '{'cudalucas/gpu' + computer_number + '.out'}'\n",
    "  elif output_type.startswith('GPU'):\n",
    "    print('\\nStarting MPrime\\n')\n",
    "    !cd mprime_gpu; nohup ./mprime -A{computer_number} -d >> '{'cpu' + computer_number + '.out'}' &\n",
    "    print('\\nStarting CUDALucas\\n')\n",
    "    !cd cudalucas && tail '{'primenet' + computer_number + '.out'}' '{'gpu' + computer_number + '.out'}'\n",
    "    !cd cudalucas && ./CUDALucas -k -i '{'CUDALucas' + computer_number + '.ini'}' | tee -ia '{'gpu' + computer_number + '.out'}'\n",
    "  elif output_type.startswith('CPU'):\n",
    "    print('\\nStarting CUDALucas\\n')\n",
    "    !cd cudalucas; nohup ./CUDALucas -i '{'CUDALucas' + computer_number + '.ini'}' >> '{'gpu' + computer_number + '.out'}' &\n",
    "    print('\\nStarting MPrime\\n')\n",
    "    !cd mprime_gpu && ./mprime -A{computer_number} -d | tee -ia '{'cpu' + computer_number + '.out'}'\n",
    "\n",
    "\n",
    "def install():\n",
    "  '''Download/Install/Configure CUDALucas then MPrime.'''\n",
    "  !wget -nv -O master.zip https://github.com/tdulcet/Distributed-Computing-Scripts/archive/master.zip\n",
    "  !unzip -o master.zip\n",
    "\n",
    "  print('\\nDownloading, building and setting up CUDALucas\\n')\n",
    "  !cp Distributed-Computing-Scripts-master/{cudalucas2.sh,primenet.py,idletime.sh} .\n",
    "  !sed -i '/^GPU=/,/^fi/ s/^/# /' cudalucas2.sh # Do not check for an Nvidia GPU\n",
    "  !sed -i '/^[[:blank:]]*if ! COMPUTE=/,/^[[:blank:]]*fi/!b; /^[[:blank:]]*fi/a echo \"$COMPUTE\"' cudalucas2.sh # Output CUDA compute capability of GPU\n",
    "  !sed -i 's/\\/$COMPUTE/\\/-gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80/' cudalucas2.sh\n",
    "  !sed -i '/^\\.\\/CUDALucas / s/^/# /' cudalucas2.sh # Disable optimization step for faster install\n",
    "  !sed -i '/^timeout / s/^/echo \"Skipped\" # /' cudalucas2.sh # Disable optimization step for faster install\n",
    "  !sed -i '/^nohup / s/^/echo \"Skipped\" # /' cudalucas2.sh # Do not start PrimeNet\n",
    "  !sed -i '/^python3 -OO / s/^/echo \"Skipped\" # /' cudalucas2.sh # Do not start PrimeNet\n",
    "  !bash -- cudalucas2.sh {computer_number} '{prime_ID}' '{computer_name}' {GPU_type_of_work}\n",
    "  print('\\nRegistering computer with PrimeNet\\n')\n",
    "  !cd cudalucas && python3 -OO primenet.py -t 0 --checkin 1 -W 1 -T {GPU_type_of_work} -u '{prime_ID}' -i '{'worktodo' + computer_number + '.txt'}' -r '{'results' + computer_number + '.txt'}' -l '{'local' + computer_number + '.ini'}' --cudalucas '{'gpu' + computer_number + '.out'}' -H '{computer_name}'\n",
    "  !cp -u Distributed-Computing-Scripts-master/google-colab/gpu_optimizations/* cudalucas/\n",
    "\n",
    "  print('\\nDownloading and setting up MPrime\\n')\n",
    "  !cp Distributed-Computing-Scripts-master/{mprime2.sh,mprime2.exp} .\n",
    "  !sed -i 's/\"mprime\"/\"mprime_gpu\"/' mprime2.sh # Name the folder specific to the runtime type\n",
    "  !sed -i '/^\\.\\/mprime / s/^/echo \"Skipped\" # /' mprime2.sh # Do not start MPrime\n",
    "  !sed -i '/^nohup / s/^/echo \"Skipped\" # /' mprime2.sh # Do not start MPrime\n",
    "  !sed -i '/^expect {/a \\\\t\"Max emergency memory in GiB/worker (*):\" { sleep 1; send -- \"3\\\\r\"; exp_continue }\\n\\t\"Get occasional proof certification work (*):\" { sleep 1; send -- \"CPU_PROOF_CERTIFICATION_WORK\\\\r\"; exp_continue }\\n\\t\"Minutes between disk writes (*):\" { sleep 1; send -- \"10\\\\r\"; exp_continue }\\n\\t\"Days of work to queue up (*):\" { sleep 1; send -- \"1\\\\r\"; exp_continue }' mprime2.exp\n",
    "  !sed -i 's/CPU_PROOF_CERTIFICATION_WORK/'$CPU_proof_certification_work'/' mprime2.exp\n",
    "  !sed -i 's/0.25/0.125/' mprime2.exp\n",
    "  if os.path.exists('mprime_gpu'):\n",
    "    os.chmod('mprime_gpu/mprime', 0o777)\n",
    "  !bash -- mprime2.sh {computer_number} '{prime_ID}' '{computer_name}' {CPU_type_of_work} # Run script\n",
    "  file = f'mprime_gpu/prim{int(computer_number):04d}.txt'\n",
    "  !echo 'FixedHardwareUID=1' > temp.txt\n",
    "  !echo 'KeepPminus1SaveFiles=0' >> temp.txt\n",
    "  if CPU_prp_proof_power != 'Default':\n",
    "    !echo 'ProofPower={CPU_prp_proof_power}' >> temp.txt\n",
    "  if CPU_prp_proof_power_mult != 'Default':\n",
    "    !echo 'ProofPowerMult={CPU_prp_proof_power_mult}' >> temp.txt\n",
    "  !echo 'PreallocateDisk=0' >> temp.txt\n",
    "  !cat '{file}' >> temp.txt\n",
    "  !mv temp.txt '{file}'\n",
    "  run()\n",
    "\n",
    "\n",
    "def debug_exit():\n",
    "  '''Output GPU and output of MPrime or CUDALucas output.'''\n",
    "  if debug.startswith('GPU') and os.path.exists(f'cudalucas/gpu{computer_number}.out'):\n",
    "    print(f'\\nOutput for computer number {computer_number}:\\n')\n",
    "    print('\\nPrimeNet output:\\n')\n",
    "    !tail -n 100 '{'cudalucas/primenet' + computer_number + '.out'}' # view primenet output\n",
    "    print('\\nGPU (CUDALucas) output: ')\n",
    "    !tail -n 100 '{'cudalucas/gpu' + computer_number + '.out'}' # view CUDALucas progress\n",
    "    !cd cudalucas && python3 -OO primenet.py -l '{'local' + computer_number + '.ini'}' -s\n",
    "    print()\n",
    "  elif debug.startswith('CPU') and os.path.exists(f'mprime_gpu/cpu{computer_number}.out'):\n",
    "    print('\\nCPU (MPrime) output:\\n')\n",
    "    !tail -n 100 '{'mprime_gpu/cpu' + computer_number + '.out'}' # view MPrime progress\n",
    "    os.chmod('mprime_gpu/mprime', 0o777)\n",
    "    !cd mprime_gpu && ./mprime -s -A{computer_number}\n",
    "    print()\n",
    "  else:\n",
    "    print(f'No {debug!r} output file found for debug option and computer number {computer_number!r}.\\n')\n",
    "\n",
    "\n",
    "def load_drive():\n",
    "  '''Load & cd into gdrive for persistent data.'''\n",
    "  global path_dir\n",
    "  if os.path.exists('/content/drive/My Drive'):  # create your own notebook with our code\n",
    "    %cd \"/content/drive/My Drive\"\n",
    "    path_dir = '/content/drive/My Drive/GIMPS/'\n",
    "  else:  # use our notebook\n",
    "    print('Warning: Google Drive is not mounted')\n",
    "    print(\n",
    "      'If you were not expecting this, on the far left click the folder icon, the \"Mount Drive\" folder button, select \"Connect to Google Drive\" '\n",
    "    )\n",
    "    print('and then re-execute this cell.')\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/gdrive')\n",
    "    %cd \"/content/gdrive/My Drive\"\n",
    "    path_dir = '/content/gdrive/My Drive/GIMPS/'\n",
    "  if 'My Drive/GIMPS' in os.getcwd():  # don't create a subfolder in GIMPS/\n",
    "    return\n",
    "  os.makedirs('GIMPS', exist_ok=True)\n",
    "  %cd \"GIMPS\"\n",
    "\n",
    "\n",
    "def gpu_check():\n",
    "  '''GPU Check.'''\n",
    "  global gpu_info\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "  if gpu_info.find('failed') >= 0:\n",
    "    print('Select the \"Runtime\" ‚Üí \"Change runtime type\" ‚Üí \"GPU\" ‚Üí \"Save\" to enable a GPU accelerator, ')\n",
    "    print('and then re-execute this cell.')\n",
    "    raise StopExecution\n",
    "  print(f'\\nGraphics Processor (GPU):\\t{gpu_info}\\n')\n",
    "\n",
    "\n",
    "gpu_check()\n",
    "!wget -qO - https://raw.github.com/tdulcet/Linux-System-Information/master/info.sh | bash -s # Check System Info\n",
    "!python3 -V\n",
    "print()\n",
    "load_drive()\n",
    "\n",
    "# set local time\n",
    "!rm -f /etc/localtime\n",
    "!ln -s {'/usr/share/zoneinfo/US/' + local_time} /etc/localtime\n",
    "\n",
    "# use/cleanup input from user\n",
    "prime_ID = 'psu' if prime_ID.lower() == 'default' else prime_ID\n",
    "computer_name = '' if computer_name.lower() == 'default' else computer_name\n",
    "computer_number = '1' if computer_number.lower().startswith('default') else computer_number.strip()\n",
    "CPU_type_of_work = CPU_type_of_work.split('-', 1)[0].rstrip()\n",
    "CPU_proof_certification_work = 'y' if CPU_proof_certification_work else 'n'\n",
    "GPU_type_of_work = GPU_type_of_work.split('-', 1)[0].rstrip()\n",
    "debug = False if debug == 'False' else debug\n",
    "\n",
    "\n",
    "if debug:\n",
    "  debug_exit()\n",
    "  raise StopExecution\n",
    "\n",
    "if not computer_number.isdigit() or int(computer_number) < 0:\n",
    "  print('ERROR: Computer number must be a number')\n",
    "  raise StopExecution\n",
    "\n",
    "elif os.path.exists(f'mprime_gpu/work{int(computer_number):04d}.txt') and os.path.exists(f'cudalucas/local{computer_number}.ini'):\n",
    "  !cd mprime_gpu && echo -e \"$(date)\\t$(sed -n 's/^model name[[:space:]]*: *//p' /proc/cpuinfo | uniq)  $(sed -n 's/^model[[:space:]]*: *//p' /proc/cpuinfo | uniq)\" >> cpus.txt\n",
    "  print('\\nPrevious CPU counts')\n",
    "  !cd mprime_gpu; cut -f 2 cpus.txt | sort | uniq -c | sort -nr\n",
    "  !cd cudalucas && echo -e \"$(date)\\t$gpu_info\" >> gpus.txt\n",
    "  print('\\nPrevious GPU counts')\n",
    "  !cd cudalucas; cut -f 2 gpus.txt | sort | uniq -c | sort -nr\n",
    "  run()\n",
    "\n",
    "else:\n",
    "  install()\n",
    "\n",
    "print('Gracefully exiting...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
